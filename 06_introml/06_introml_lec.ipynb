{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:image width px; font-size:75%; text-align:right;\">\n",
    "    <img src=\"img/danielle-macinnes-IuLgi9PWETU-unsplash.jpg\" width=\"width\" height=\"height\" style=\"padding-bottom:0.2em;\" />\n",
    "    <figcaption>Photo by Danielle MacInnes on Unsplash</figcaption>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning\n",
    "\n",
    "**Applied Programming - Summer term 2022 - FOM Hochschule f√ºr Oekonomie und Management - Cologne**\n",
    "\n",
    "**Lecture 06 - April 29, 2022**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Dennis Gluesenkamp*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* [Introduction](#introduction)\n",
    "* [Dataset creation](#datasetcreation)\n",
    "    * [Classification](#datasetcreation_classification)\n",
    "    * [Regression](#datasetcreation_regression)\n",
    "* [The decision tree as the first reference model](#decisiontree)\n",
    "    * [Classification](#decisiontree_classification)\n",
    "    * [Regression](#decisiontree_regression)\n",
    "* [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction<a class=\"anchor\" id=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation<a class=\"anchor\" id=\"datasetcreation\"></a>\n",
    "In order to get a step-by-step understanding of the topic, application and functionality of Machine Learning, we will first use artificially generated data sets for initial, simple models. This allows us to get to know the structure of modeling with scikit-learn and thus forms the basis for later, more complex applications. The generated datasets may be focused on classification or regression problems and include features that do not claim to represent real values of any particular magnitude or characteristic. Thus, they are simply numerical columns without (physical) units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification<a class=\"anchor\" id=\"datasetcreation_classification\"></a>\n",
    "First, we want to generate a dataset for a classification problem, and we can call the ``make_classification()`` function to do this, which is located in the ``datasets`` module of scikit-learn. [[1]](#sklearn2021a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check output of function directly\n",
    "make_classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(make_classification()[0]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(make_classification()[1]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0, y0 = make_classification(n_features           = 2,\n",
    "                             n_informative        = 2,\n",
    "                             n_redundant          = 0,\n",
    "                             n_repeated           = 0,\n",
    "                             n_clusters_per_class = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X0.shape)\n",
    "print(y0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X0[:, 0], X0[:, 1],\n",
    "            marker = 'o',\n",
    "            c      = y0)\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Xc, yc = make_classification(n_features           = 6,\n",
    "                             n_informative        = 4,\n",
    "                             n_redundant          = 0,\n",
    "                             n_repeated           = 0,\n",
    "                             n_clusters_per_class = 1,\n",
    "                             random_state         = 123)\n",
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.subplots_adjust(wspace = .5, hspace = .5)\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.scatter(Xc[:, 0], Xc[:, 1],\n",
    "            marker = 'o',\n",
    "            c      = yc)\n",
    "plt.title('X_0 vs. X_1')\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.scatter(Xc[:, 0], Xc[:, 2],\n",
    "            marker = 'o',\n",
    "            c      = yc)\n",
    "plt.title('X_0 vs. X_2')\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.scatter(Xc[:, 0], Xc[:, 3],\n",
    "            marker = 'o',\n",
    "            c      = yc)\n",
    "plt.title('X_0 vs. X_3')\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.scatter(Xc[:, 1], Xc[:, 2],\n",
    "            marker = 'o',\n",
    "            c      = yc)\n",
    "plt.title('X_1 vs. X_2')\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.scatter(Xc[:, 1], Xc[:, 3],\n",
    "            marker = 'o',\n",
    "            c      = yc)\n",
    "plt.title('X_1 vs. X_3')\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.scatter(Xc[:, 2], Xc[:, 3],\n",
    "            marker = 'o',\n",
    "            c      = yc)\n",
    "plt.title('X_2 vs. X_3')\n",
    "\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = pd.DataFrame(np.c_[Xc, yc])\n",
    "dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(dfc, hue = 6, markers=['o', 's'])\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression<a class=\"anchor\" id=\"datasetcreation_regression\"></a>\n",
    "In the second step, we also create a randomly generated regression problem. Here we access the function ``make_regression()``, which works analogously to the one from the classification [[1]](#sklearn2021a). We keep the most defaults. The only exception is the number of features, because we want to be able to plot the distributions of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "make_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xr, yr = make_regression(n_features   = 5,\n",
    "                         random_state = 123)\n",
    "\n",
    "dfr = pd.DataFrame(np.c_[Xr, yr])\n",
    "sns.pairplot(dfr, hue = 5, palette = 'icefire', diag_kind = None)\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises<a class=\"anchor\" id=\"datasetcreation_exercises\"></a>\n",
    "1. Go to the User Guide of scikit-learn to the chapter of \"Toy Datasets designed for training\" [[2]](#sklearn2021b). Now select one dataset each for regression and classification from the datasets offered there and familiarize yourself with the parameter ``return_X_y`` and (if available) ``as_frame`` and use them appropriately.\n",
    "2. Import the necessary modules for the datasets you selected and create the data for each, as shown above for the generators. Choose some appropriate names which are different to the names for the generator datasets above.\n",
    "3. Create a pairplot for each of the regression and classification and evaluate the results. **Be careful:** Using a dataset with a lot of features can lead to an extensive calcultation time! As an alternative, you can plot only some of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The decision tree as the first reference model<a class=\"anchor\" id=\"decisiontree\"></a>\n",
    "Up to this point, we have only created sample data. Modeling is thus still pending. In order to understand the basic principle of machine learning algorithms on the one hand and to get to know the basic implementation of these algorithms in Python respectively scikit-learn on the other hand, we consider the decision tree as an example. [[3]](#sklearn2021c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of decision trees in scikit-learn allows their use for both classifications and regressions. This provides us with a tool for solving the problems created above, which may not lead to the best solution in many cases. However, decision trees have a high practical value due to their illustrativeness as well as the straightforward realization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification<a class=\"anchor\" id=\"decisiontree_classification\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test set first\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(Xc, yc,\n",
    "                                                        test_size    = 0.2,\n",
    "                                                        random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xc_train.shape)\n",
    "print(Xc_test.shape)\n",
    "print(yc_train.shape)\n",
    "print(yc_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(Xc_train, yc_train)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,15))\n",
    "tree.plot_tree(clf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_pred = clf.predict(Xc_test)\n",
    "print(yc_pred)\n",
    "print(yc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(clf, Xc_test, yc_test)  \n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(yc_test, yc_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression<a class=\"anchor\" id=\"decisiontree_regression\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xr_train, Xr_test, yr_train, yr_test = train_test_split(Xr, yr,\n",
    "                                                        test_size    = 0.2,\n",
    "                                                        random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xr_train.shape)\n",
    "print(Xr_test.shape)\n",
    "print(yr_train.shape)\n",
    "print(yr_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = tree.DecisionTreeRegressor()\n",
    "regr.fit(Xr_train, yr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_pred = regr.predict(Xr_test)\n",
    "print(yr_pred)\n",
    "print(yr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(yr_test, yr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,8))\n",
    "plt.scatter(Xr_test[:, 1], yr_test,\n",
    "            s = 50, color = 'blue', label = \"test\")\n",
    "plt.scatter(Xr_test[:, 1], yr_pred,\n",
    "            s = 50, color = 'orange', label = 'pred')\n",
    "plt.xlabel('Objects, X')\n",
    "plt.ylabel(\"Target, y\")\n",
    "plt.title(\"Decision Tree Regression\")\n",
    "plt.legend()\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises<a class=\"anchor\" id=\"decisiontree_exercises\"></a>\n",
    "1. Create a decision tree for each of the regression and classification problems you selected earlier from the Toy Datasets and interpret the result. Use only the default parameters of the tree.\n",
    "2. Try to manually improve your result from 1. with the parameters of the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References<a class=\"anchor\" id=\"references\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1]<a class=\"anchor\" id=\"sklearn2021a\"></a> The scikit-learn developers (2021). 7.3. Generated datasets. Retrieved 2021-04-18 from https://scikit-learn.org/stable/datasets/sample_generators.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2]<a class=\"anchor\" id=\"sklearn2021b\"></a> The scikit-learn developers (2021). 7.1. Toy datasets. Retrieved 2021-04-18 from https://scikit-learn.org/stable/datasets/toy_dataset.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3]<a class=\"anchor\" id=\"sklearn2021c\"></a> The scikit-learn developers (2021). 1.10. Decision Trees. Retrieved 2021-04-18 from https://scikit-learn.org/stable/modules/tree.html#decision-trees"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
