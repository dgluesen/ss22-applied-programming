{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:image width px; font-size:75%; text-align:right;\">\n",
    "    <img src=\"img/pexels-brandon-montrone-1179229.jpg\" width=\"width\" height=\"height\" style=\"padding-bottom:0.2em;\" />\n",
    "    <figcaption>Photo by Kaique Rocha on Pexels</figcaption>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 2\n",
    "\n",
    "**Applied Programming - Summer term 2022 - FOM Hochschule f√ºr Oekonomie und Management - Cologne**\n",
    "\n",
    "**Lecture 08 - May 12, 2022**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Dennis Gluesenkamp*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* [Dataset recap](#datarecap)\n",
    "* [Regression](#regression)\n",
    "    * [Linear regression](#regression_linear)\n",
    "    * [Lasso](#regression_lasso)\n",
    "    * [Random forest regressor](#regression_rf)\n",
    "* [Clustering](#clustering)\n",
    "    * [kMeans](#clustering_kmeans)\n",
    "    * [Alternative](#clustering_alternative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset recap<a class=\"anchor\" id=\"datarecap\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artificial classification problem:\n",
    "X_c, y_c = make_classification(n_samples            = 1000,\n",
    "                               n_features           = 10,\n",
    "                               n_redundant          = 2,\n",
    "                               n_informative        = 5,\n",
    "                               n_classes            = 3,\n",
    "                               n_clusters_per_class = 3,\n",
    "                               flip_y               = 0.05,\n",
    "                               shift                = None,\n",
    "                               random_state         = 42)\n",
    "\n",
    "# Artificial regression problem:\n",
    "X_r, y_r = make_regression(n_samples     = 1000,\n",
    "                           n_features    = 10,\n",
    "                           n_informative = 5,\n",
    "                           noise         = 0.05,\n",
    "                           random_state  = 42)\n",
    "\n",
    "# Scikit-learn toy dataset for classification:\n",
    "X_b, y_b = load_breast_cancer(return_X_y = True)\n",
    "\n",
    "# Scikit-learn toy dataset for regression:\n",
    "X_d, y_d = load_diabetes(return_X_y = True)\n",
    "\n",
    "# Kaggle dataset for regression:\n",
    "# Medical Cost Personal Datasets - Insurance Forecast by using Linear Regression\n",
    "# https://www.kaggle.com/mirichoi0218/insurance\n",
    "df_i = pd.read_csv('dat/insurance.csv')\n",
    "\n",
    "# Preprocessing\n",
    "df_i_enc = pd.get_dummies(df_i, drop_first = True)\n",
    "\n",
    "X_c_train, X_c_test, y_c_train, y_c_test = train_test_split(X_c, y_c,\n",
    "                                                            test_size = 0.25,\n",
    "                                                            random_state = 42)\n",
    "\n",
    "X_r_train, X_r_test, y_r_train, y_r_test = train_test_split(X_r, y_r,\n",
    "                                                            test_size = 0.25,\n",
    "                                                            random_state = 42)\n",
    "\n",
    "X_b_train, X_b_test, y_b_train, y_b_test = train_test_split(X_b, y_b,\n",
    "                                                            test_size = 0.3,\n",
    "                                                            random_state = 42)\n",
    "\n",
    "X_d_train, X_d_test, y_d_train, y_d_test = train_test_split(X_d, y_d,\n",
    "                                                            test_size = 0.3,\n",
    "                                                            random_state = 42)\n",
    "\n",
    "df_i_train, df_i_test = train_test_split(df_i_enc,\n",
    "                                         test_size = 0.05,\n",
    "                                         random_state = 42)\n",
    "\n",
    "st_scaler = StandardScaler()\n",
    "df_i_train_scaled = pd.DataFrame(st_scaler.fit_transform(df_i_train),\n",
    "                                 columns = df_i_train.columns)\n",
    "df_i_test_scaled  = pd.DataFrame(st_scaler.transform(df_i_test),\n",
    "                                 columns = df_i_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression<a class=\"anchor\" id=\"regression\"></a>\n",
    "In this second part we deal with regression. This is about the prediction of continuous values in contrast to classification with discrete groups. It follows directly that the target must be a numerical expression. An example of a regression problem is the prediction of prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression<a class=\"anchor\" id=\"regression_linear\"></a>\n",
    "The classic and simplest regression approach is linear regression. This is the representation of the target variable as a linear combination of the independent variables according to the following mathematical form.\n",
    "\\begin{equation*}\n",
    "y\\left(c,x\\right) = c_0 + c_1 x_1 + \\dots + c_n x_n\n",
    "\\end{equation*}\n",
    "Here, $c = \\left(c_0, c_1, \\dots, c_n\\right)$ is coefficient vector. The model adjusts the coefficients to minimize the sum of squares of real and approximated targets, which corresponds to the mathematical minimization problem\n",
    "\\begin{equation*}\n",
    "\\min_{c} \\| Xc - Y \\|^2.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "# Artificial regression problem\n",
    "reg.fit(X_r_train, y_r_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the coefficient of determination for test dataset\n",
    "reg.score(X_r_test, y_r_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(reg.coef_)\n",
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of feature\n",
    "i = 0\n",
    "plt.figure(figsize = (15,8))\n",
    "plt.scatter(X_r_test[:, i], y_r_test,\n",
    "            s = 50, marker = '^', color = 'blue', label = 'test', alpha = 0.6)\n",
    "plt.scatter(X_r_test[:, i], reg.predict(X_r_test),\n",
    "            s = 70, marker = 'v', color = 'orange', label = 'pred', alpha = 0.5)\n",
    "plt.xlabel('Objects, X, feature ' + str(i))\n",
    "plt.ylabel(\"Target, y\")\n",
    "plt.title(\"Linear regression\")\n",
    "plt.legend()\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diabetes dataset\n",
    "reg.fit(X_d_train, y_d_train)\n",
    "reg.score(X_d_test, y_d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg.coef_)\n",
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of variable\n",
    "i = 2\n",
    "plt.figure(figsize = (15,8))\n",
    "plt.scatter(X_d_test[:, i], y_d_test,\n",
    "            s = 50, marker = '^', color = 'blue', label = 'test', alpha = 0.6)\n",
    "plt.scatter(X_d_test[:, i], reg.predict(X_d_test),\n",
    "            s = 70, marker = 'v', color = 'orange', label = 'pred', alpha = 0.5)\n",
    "plt.xlabel('Objects, X, feature ' + str(i))\n",
    "plt.ylabel('Target, y')\n",
    "plt.title('Linear regression')\n",
    "plt.legend()\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest regressor<a class=\"anchor\" id=\"regression_rf\"></a>\n",
    "We have already learned about Random Forests as a classification algorithm. However, they can also be used for regression problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf     = RandomForestRegressor(random_state = 42)\n",
    "params = {'n_estimators': [50, 100, 200],\n",
    "          'criterion':    ['mse', 'mae'],\n",
    "          'max_depth':    [2, 4, 6, 8]}\n",
    "k      = 3\n",
    "\n",
    "reg = GridSearchCV(rf, params, cv = k)\n",
    "reg.fit(X_d_train, y_d_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(X_d_test, y_d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(reg.cv_results_).sort_values(by = ['rank_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of variable\n",
    "i = 2\n",
    "plt.figure(figsize = (15,8))\n",
    "plt.scatter(X_d_test[:, i], y_d_test,\n",
    "            s = 50, marker = '^', color = 'blue', label = 'test', alpha = 0.6)\n",
    "plt.scatter(X_d_test[:, i], reg.predict(X_d_test),\n",
    "            s = 70, marker = 'v', color = 'orange', label = 'pred', alpha = 0.5)\n",
    "plt.xlabel('Objects, X, feature ' + str(i))\n",
    "plt.ylabel('Target, y')\n",
    "plt.title('Random forest regression')\n",
    "plt.legend()\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises\n",
    "Train one random forest regressor model and another one of your choice for the insurance dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering<a class=\"anchor\" id=\"clustering\"></a>\n",
    "We will conclude the two lectures on machine learning with a method of unsupervised learning, namely clustering. This refers to the discovery of structures in the data set that exhibit similarities between objects. The objects found in this way are assigned to groups called clusters. Clustering thus aims at new findings that were not previously available. The algorithm formed in this way can also be applied to previously unknown data in order to make an appropriate assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kMeans<a class=\"anchor\" id=\"clustering_kmeans\"></a>\n",
    "Apply the k-means algorithm to arbitrary high-dimensional data. The method first chooses $k$ centers as the starting points. Then, an assignment of the objects in the data set to these centers is performed. This is done based on the distance of the objects to the centers. Subsequently, the cluster centers are recalculated based on the points. The assignment and recalculation is then repeated until there is no change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 8))\n",
    "plt.scatter(X_c[:, 0], X_c[:, 4], s = 25, c = y_c, alpha = 0.6)\n",
    "plt.xlabel('X_0')\n",
    "plt.ylabel('X_4')\n",
    "plt.title('Artificial classification problem')\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "y_c_pred = KMeans(n_clusters = 3, n_init = 100, max_iter = 1000, random_state = 42).fit_predict(X_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.concat([pd.DataFrame(X_c), pd.DataFrame(y_c), pd.DataFrame(y_c_pred)], axis = 1)\n",
    "df_c.columns = ['X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'y', 'y_pred']\n",
    "df_c.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 3, figsize = (15, 8))\n",
    "ax[0].scatter(df_c[df_c['y'] == 0]['X0'], df_c[df_c['y'] == 0]['X4'],\n",
    "              s = 25, c = df_c[df_c['y'] == 0]['y_pred'], alpha = 0.7)\n",
    "ax[0].set_title('Class 0')\n",
    "ax[1].scatter(df_c[df_c['y'] == 1]['X0'], df_c[df_c['y'] == 1]['X4'],\n",
    "              s = 25, c = df_c[df_c['y'] == 1]['y_pred'], alpha = 0.7)\n",
    "ax[1].set_title('Class 1')\n",
    "ax[2].scatter(df_c[df_c['y'] == 2]['X0'], df_c[df_c['y'] == 2]['X4'],\n",
    "              s = 25, c = df_c[df_c['y'] == 2]['y_pred'], alpha = 0.7)\n",
    "ax[2].set_title('Class 2')\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative<a class=\"anchor\" id=\"clustering_alternative\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "y_c_pred = AgglomerativeClustering(n_clusters = 3).fit_predict(X_c)\n",
    "\n",
    "df_c = pd.concat([pd.DataFrame(X_c), pd.DataFrame(y_c), pd.DataFrame(y_c_pred)], axis = 1)\n",
    "df_c.columns = ['X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'y', 'y_pred']\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 3, figsize = (15, 8))\n",
    "ax[0].scatter(df_c[df_c['y'] == 0]['X0'], df_c[df_c['y'] == 0]['X4'],\n",
    "              s = 25, c = df_c[df_c['y'] == 0]['y_pred'], alpha = 0.7)\n",
    "ax[0].set_title('Class 0')\n",
    "ax[1].scatter(df_c[df_c['y'] == 1]['X0'], df_c[df_c['y'] == 1]['X4'],\n",
    "              s = 25, c = df_c[df_c['y'] == 1]['y_pred'], alpha = 0.7)\n",
    "ax[1].set_title('Class 1')\n",
    "ax[2].scatter(df_c[df_c['y'] == 2]['X0'], df_c[df_c['y'] == 2]['X4'],\n",
    "              s = 25, c = df_c[df_c['y'] == 2]['y_pred'], alpha = 0.7)\n",
    "ax[2].set_title('Class 2')\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
